{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -e ../../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmexp.models.implementations.gpt2small import GPT2Tokenizer, ProbedGPT2\n",
    "from lmexp.generic.probing import train_probe\n",
    "from lmexp.generic.caa import get_caa_vecs\n",
    "from lmexp.generic.hooked_model import run_simple_steering\n",
    "from datetime import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model and tokenizer\n",
    "\n",
    "These classes have already implemented all the probing-related methods so we won't have to add more hooks + they are ready to use with our vector extraction and steering functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ProbedGPT2()\n",
    "tokenizer = GPT2Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_n_layers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a linear probe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate some data\n",
    "\n",
    "Let's see whether we can get a date/time probe vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_labeled_text(n):\n",
    "    # date as text, date as utc timestamp in seconds, sample randomly from between 1990 and 2022\n",
    "    start_timestamp = datetime(2013, 1, 1).timestamp()\n",
    "    end_timestamp = datetime(2016, 1, 1).timestamp()\n",
    "    labeled_text = []\n",
    "    for i in range(n):\n",
    "        timestamp = start_timestamp + (end_timestamp - start_timestamp) * random.random()\n",
    "        date = datetime.fromtimestamp(timestamp)\n",
    "        # date like \"Monday 15th November 2021 8AM\"\n",
    "        text = date.strftime(\"Today is a %A. It's the %dth of %B, %Y. The time is %I %p. This is the point in time when\")\n",
    "        label = timestamp\n",
    "        labeled_text.append((text, label))\n",
    "    # normalize labels to have mean 0 and std 1\n",
    "    labels = [label for _, label in labeled_text]\n",
    "    mean = sum(labels) / len(labels)\n",
    "    std = (sum((label - mean) ** 2 for label in labels) / len(labels)) ** 0.5\n",
    "    labeled_text = [(text, (label - mean) / std) for text, label in labeled_text]\n",
    "    return labeled_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Today is a Sunday. It's the 19th of April, 2015. The time is 08 AM. This is the point in time when\", 0.9344513470153523)\n"
     ]
    }
   ],
   "source": [
    "data = gen_labeled_text(10_000)\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 15.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, mean loss: 4.097890421295166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 15.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, mean loss: 0.9344183967590332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, mean loss: 0.8330812377929687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 15.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, mean loss: 0.7460678833007812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 15.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, mean loss: 0.6499895660400391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, mean loss: 0.5841311962127685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 15.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, mean loss: 0.4985210781097412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 15.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, mean loss: 0.459724365234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 15.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, mean loss: 0.3679254432678223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 15.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, mean loss: 0.3543036449432373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 15.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, mean loss: 0.29407937202453616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 15.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, mean loss: 0.25365611743927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, mean loss: 0.2445849018096924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 15.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, mean loss: 0.2106756420135498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 15.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, mean loss: 0.2012092818260193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 15.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, mean loss: 0.21058159761428832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 15.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, mean loss: 0.1422152379989624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 15.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, mean loss: 0.13628376512527465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 15.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, mean loss: 0.11741883687973022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 15.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, mean loss: 0.1060804295539856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "probe = train_probe(\n",
    "    labeled_text=data,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    layer=4,\n",
    "    n_epochs=20,\n",
    "    batch_size=128,\n",
    "    lr=1e-2,\n",
    "    save_to=None,\n",
    "    token_position=-2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction = probe.weight[0]\n",
    "bias = probe.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.0246], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': 'The current date is',\n",
       "  'output': 'The current date is the date of the first occurrence',\n",
       "  'layer': 4,\n",
       "  'multiplier': -3}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_simple_steering(\n",
    "    text=[\"The current date is\"],\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    layer=4,\n",
    "    multiplier=-3,\n",
    "    vector=direction.detach(),\n",
    "    max_n_tokens=10,\n",
    "    save_to=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': 'The current date is',\n",
       "  'output': 'The current date is the next year, the next',\n",
       "  'layer': 4,\n",
       "  'multiplier': 4}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_simple_steering(\n",
    "    text=[\"The current date is\"],\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    layer=4,\n",
    "    multiplier=4,\n",
    "    vector=direction.detach(),\n",
    "    max_n_tokens=10,\n",
    "    save_to=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get some contrast pairs\n",
    "\n",
    "Let's try an easy direction - positive vs negative sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOD = [\n",
    "    \"The weather is really nice\",\n",
    "    \"I'm so happy\",\n",
    "    \"This cake is absolutely delicious\",\n",
    "    \"I love my friends\",\n",
    "    \"I'm feeling great\",\n",
    "    \"I'm so excited\",\n",
    "    \"This is the best day ever\",\n",
    "    \"I really like this gift\",\n",
    "    \"Croissants are my favorite\",\n",
    "    \"The movie was fantastic\",\n",
    "    \"I got a promotion at work\",\n",
    "    \"My vacation was amazing\",\n",
    "    \"The concert exceeded my expectations\",\n",
    "    \"I'm grateful for my family\",\n",
    "    \"This book is incredibly engaging\",\n",
    "    \"The restaurant service was excellent\",\n",
    "    \"I'm proud of my accomplishments\",\n",
    "    \"The sunset is breathtakingly beautiful\",\n",
    "    \"I passed my exam with flying colors\",\n",
    "    \"This coffee tastes perfect\",\n",
    "]\n",
    "\n",
    "BAD = [\n",
    "    \"The weather is really bad\",\n",
    "    \"I'm so sad\",\n",
    "    \"This cake is completely inedible\",\n",
    "    \"I hate my enemies\",\n",
    "    \"I'm feeling awful\",\n",
    "    \"I'm so anxious\",\n",
    "    \"This is the worst day ever\",\n",
    "    \"I dislike this gift\",\n",
    "    \"Croissants are disgusting\",\n",
    "    \"The movie was terrible\",\n",
    "    \"I got fired from work\",\n",
    "    \"My vacation was a disaster\",\n",
    "    \"The concert was a huge disappointment\",\n",
    "    \"I'm frustrated with my family\",\n",
    "    \"This book is incredibly boring\",\n",
    "    \"The restaurant service was horrible\",\n",
    "    \"I'm ashamed of my mistakes\",\n",
    "    \"The weather is depressingly gloomy\",\n",
    "    \"I failed my exam miserably\",\n",
    "    \"This coffee tastes awful\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\n",
    "    (text, True) for text in GOOD\n",
    "] + [\n",
    "    (text, False) for text in BAD\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the CAA vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 109.17it/s]\n"
     ]
    }
   ],
   "source": [
    "vectors = get_caa_vecs(\n",
    "    labeled_text=dataset,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    layers=range(3, 8),\n",
    "    save_to=None              \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the CAA vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': 'I think that this cat is',\n",
       "  'output': \"I think that this cat is a bit of a mess. It's not a good cat. It\",\n",
       "  'layer': 6,\n",
       "  'multiplier': -2}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_simple_steering(\n",
    "    text=[\"I think that this cat is\"],\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    layer=6,\n",
    "    multiplier=-2,\n",
    "    vector=vectors[6],\n",
    "    max_n_tokens=20,\n",
    "    save_to=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': 'I think that this cat is',\n",
       "  'output': 'I think that this cat is a great addition to the collection of cats that we have in our collection',\n",
       "  'layer': 6,\n",
       "  'multiplier': 2}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_simple_steering(\n",
    "    text=[\"I think that this cat is\"],\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    layer=6,\n",
    "    multiplier=2,\n",
    "    vector=vectors[6],\n",
    "    max_n_tokens=20,\n",
    "    save_to=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
